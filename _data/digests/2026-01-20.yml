date: "2026-01-20"
title: "Daily Digest — 2026-01-20"
title_zh: "每日简报 — 2026-01-20"
note: "I’m trying to build a small habit: skim widely, then pick 1–2 things to unpack properly."
note_zh: "我在试一个小习惯：先广泛扫一圈，再挑 1–2 条认真展开。"
items:
  - category: "AI frontier"
    title: "Differential Transformer V2"
    title_zh: "Differential Transformer V2"
    why: "A new attention variant aimed at more efficient long-context modeling."
    why_zh: "一种新的注意力变体，聚焦更高效的长上下文建模。"
    takeaway: "Proposes a differential attention mechanism (Diff Attn v2) to improve long-context efficiency; a useful reference point when benchmarking attention variants against standard Transformers."
    takeaway_zh: "提出一种差分注意力机制（Diff Attn v2）以提升长上下文的效率；可作为对比不同注意力变体与标准 Transformer 的基准参考。"
    prompt: ""
    prompt_zh: ""
    url: "https://huggingface.co/blog/microsoft/diff-attn-v2"
    source: "Hugging Face Blog"

  - category: "AI frontier"
    title: "OpenAI partners with Cerebras"
    title_zh: "OpenAI 与 Cerebras 合作"
    why: "A notable infra/inference partnership; watch for speed/cost implications."
    why_zh: "值得关注的算力/推理合作，可能影响速度与成本。"
    takeaway: "Signals continued investment in specialized inference hardware partnerships; this can reshape latency/cost trade-offs and who gets access to fast inference at scale."
    takeaway_zh: "反映出模型方继续推进与专用推理硬件的合作；这可能改变延迟/成本的权衡，并影响“高速推理”在规模化场景中的可获得性。"
    prompt: ""
    prompt_zh: ""
    url: "https://openai.com/index/cerebras-partnership"
    source: "OpenAI Blog"

  - category: "AI frontier"
    title: "Open Responses: What you need to know"
    title_zh: "Open Responses：你需要了解什么"
    why: "A practical multi-model workflow for comparing and integrating LLM outputs."
    why_zh: "一个可操作的多模型工作流，用于对比与整合大模型输出。"
    takeaway: "Presents an 'open responses' pattern for comparing multiple models and synthesizing outputs; useful for building robust pipelines with diversity + verification."
    takeaway_zh: "介绍一种“Open Responses”的模式：对比多个模型并整合输出；适合用“多样性 + 校验”来构建更稳健的工作流。"
    prompt: ""
    prompt_zh: ""
    url: "https://huggingface.co/blog/open-responses"
    source: "Hugging Face Blog"

  - category: "CSS / AI & society"
    title: "AI Sycophancy: How Users Flag and Respond"
    title_zh: "AI 迎合：用户如何标记与回应"
    why: "Empirical signals for detecting/handling overly agreeable LLM behavior."
    why_zh: "提供可观测的证据线索，帮助识别/处理过度迎合的 LLM 行为。"
    takeaway: "Studies how users notice and react to sycophantic assistant behavior; offers observable signals and implications for trust and safety evaluation."
    takeaway_zh: "研究用户如何识别并回应“迎合型”助手行为；给出可观测信号，并讨论其对信任与安全评估的启示。"
    prompt: "How should assistants balance politeness vs disagreement without drifting into sycophancy?"
    prompt_zh: "助手应如何在“礼貌”与“必要的不同意”之间平衡，而不滑向迎合？"
    url: "https://arxiv.org/abs/2601.10467v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "The Conversational Exam: A Scalable Assessment Design for the AI Era"
    title_zh: "对话式考试：AI 时代可扩展的评估设计"
    why: "An assessment format designed to stay meaningful when students have AI."
    why_zh: "一种面向 AI 时代的评估形式，尽量保持测评的有效性。"
    takeaway: "Proposes conversational exams that evaluate reasoning through interaction rather than final answers, aiming to stay meaningful when students have access to AI tools."
    takeaway_zh: "提出“对话式考试”，通过交互过程评估推理，而不只看最终答案；目标是在学生可用 AI 工具的时代保持测评有效性。"
    prompt: "What guardrails would make conversational assessment fair, scalable, and less subjective?"
    prompt_zh: "哪些规则/机制能让对话式测评更公平、可扩展、并降低主观性？"
    url: "https://arxiv.org/abs/2601.10691v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "Evaluating 21st-Century Competencies in Postsecondary Curricula with Large Language Models: Performance Benchmarking and Reasoning-Based Prompting Strategies"
    title_zh: "用大语言模型评估高等教育课程的 21 世纪能力：性能基准与推理式提示策略"
    why: "Benchmarks LLMs for curricular competency evaluation and prompting strategies."
    why_zh: "针对课程能力评估任务，对模型表现与提示策略进行基准测试。"
    takeaway: "Benchmarks LLMs for evaluating 21st-century competencies in curricula and tests reasoning-based prompting; suggests how automated curriculum auditing can be made more reliable."
    takeaway_zh: "对“课程 21 世纪能力评估”任务进行大模型基准测试，并探索推理式提示策略；为更可靠的自动化课程审计提供方法线索。"
    prompt: ""
    prompt_zh: ""
    url: "https://arxiv.org/abs/2601.10983v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "aiPlato: A Novel AI Tutoring and Step-wise Feedback System for Physics Homework"
    title_zh: "aiPlato：用于物理作业的 AI 辅导与分步反馈系统"
    why: "A tutoring design emphasizing step-wise feedback (closer to how students learn)."
    why_zh: "强调分步反馈的辅导设计，更贴近学生的学习过程。"
    takeaway: "An AI tutoring design that focuses on step-wise feedback rather than giving full solutions; a concrete pattern for scaffolding student learning."
    takeaway_zh: "一种强调“分步反馈”的 AI 辅导设计，而不是直接给出完整解答；提供了更贴近支架式学习的具体设计模式。"
    prompt: ""
    prompt_zh: ""
    url: "https://arxiv.org/abs/2601.09965v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "Take Out Your Calculators: Estimating the Real Difficulty of Question Items with LLM Student Simulations"
    title_zh: "拿出你的计算器：用“LLM 学生模拟”估计题目真实难度"
    why: "Uses simulated \"LLM students\" to estimate item difficulty for assessment design."
    why_zh: "用模拟的“LLM 学生”来估计题目难度，服务于测评设计。"
    takeaway: "Uses simulated 'LLM students' to estimate item difficulty, offering a method idea for item analysis when real response data is limited."
    takeaway_zh: "用“LLM 学生模拟”来估计题目难度；当真实作答数据不足时，为题目分析提供一种方法思路。"
    prompt: ""
    prompt_zh: ""
    url: "https://arxiv.org/abs/2601.09953v1"
    source: "arXiv"
