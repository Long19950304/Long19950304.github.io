---
layout: page
title: "Reliable LLM-Assisted Qualitative Analysis"
description: "Benchmarks, calibration, and QA for human/LLM hybrid coding in communication research."
img: /assets/img/projects/llm-evaluation.png
importance: 2
category: research
---

I work on reliability and evaluation for LLM-assisted qualitative analysis: how to design benchmarks, calibrate outputs, and run QA for complex coding tasks so results remain defensible in real research workflows.

Representative directions:
- Coding quality assessment and calibration (complex labels, multi-stage rubrics, error analysis)
- Benchmark design for domain-specific annotation tasks
- Reproducible pipelines for human/LLM hybrid coding (auditability and responsible use)
