---
layout: page
title: "每日简报 — 2026-01-20"
lang: zh
permalink: /zh/digest/2026-01-20/
digest_date: 2026-01-20
card_image: /assets/img/digests/2026-01-20-zh.png
translation_key: digest-2026-01-20
---

![Daily digest card](/assets/img/digests/2026-01-20-zh.png)

我在练一个小习惯：先扫一圈，再挑 1–2 条认真读。

## 链接

### CSS / AI 与社会

- [AI 迎合：用户如何标记与回应](https://arxiv.org/abs/2601.10467v1) - 提供可观测的证据线索，帮助识别/处理过度迎合的 LLM 行为。
  - 我的一句话: 这篇文章看用户在什么情况下会觉得模型在迎合，以及他们会怎么反馈；对做信任/安全评估挺有启发。
  - 我在想: 助手应如何在“礼貌”与“必要的不同意”之间平衡，而不滑向迎合？

### AI 前沿

- [Differential Transformer V2](https://huggingface.co/blog/microsoft/diff-attn-v2) - 一种新的注意力变体，聚焦更高效的长上下文建模。
  - 我的一句话: Diff Attn v2 这类注意力改造主要是在追求更“省算力”的长上下文；适合拿来和标准 Transformer 对照看收益与代价。
- [OpenAI 与 Cerebras 合作](https://openai.com/index/cerebras-partnership) - 值得关注的算力/推理合作，可能影响速度与成本。
  - 我的一句话: 一条基础设施新闻：模型方继续把推理压到更专用的硬件上，可能带来更低延迟/成本，也会改变“谁能用到高速推理”的格局。
- [Open Responses：你需要了解什么](https://huggingface.co/blog/open-responses) - 一个可操作的多模型工作流，用于对比与整合大模型输出。
  - 我的一句话: 一个多模型对照+整合的工作流范式：用多样性拿思路，用验证把结论收敛到更稳。

### 教育 / 学习科学 / 教育技术

- [对话式考试：AI 时代可扩展的评估设计](https://arxiv.org/abs/2601.10691v1) - 一种面向 AI 时代的评估形式，尽量保持测评的有效性。
  - 我的一句话: 把考试做成对话过程，重点评估推理与解释而不是答案本身；在学生能用 AI 工具的情况下更有意义。
  - 我在想: 哪些规则/机制能让对话式测评更公平、可扩展、并降低主观性？
- [用大语言模型评估高等教育课程的 21 世纪能力：性能基准与推理式提示策略](https://arxiv.org/abs/2601.10983v1) - 针对课程能力评估任务，对模型表现与提示策略进行基准测试。
  - 我的一句话: 用 LLM 去读课程大纲、评估能力覆盖，并比较不同提示策略；很适合作为自动化课程审计的起点。
- [aiPlato：用于物理作业的 AI 辅导与分步反馈系统](https://arxiv.org/abs/2601.09965v1) - 强调分步反馈的辅导设计，更贴近学生的学习过程。
  - 我的一句话: 强调分步提示/反馈，让学生自己走完推理链；比直接给答案更像辅导。
- [拿出你的计算器：用“LLM 学生模拟”估计题目真实难度](https://arxiv.org/abs/2601.09953v1) - 用模拟的“LLM 学生”来估计题目难度，服务于测评设计。
  - 我的一句话: 用“模拟学生”来估题目难度：当真实作答数据不够时是个替代办法，但最好配套校准/验证。
