#!/usr/bin/env python3
"""
Daily digest generator for the personal site.

Workflow:
  1) Draft candidates from RSS/Atom feeds:
       personal-site/bin/digest draft --date 2026-01-20
  2) Edit the generated YAML (fill `why` fields, delete low-signal items).
  3) Build the digest page + image card:
       personal-site/bin/digest build --date 2026-01-20
  4) (Optional) Generate social post text (X thread + LinkedIn copy):
       personal-site/bin/digest social --date 2026-01-20
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import re
import sys
import html
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Iterable

import feedparser
import yaml
from PIL import Image, ImageDraw, ImageFont


REPO_ROOT = Path(__file__).resolve().parents[1]
DATA_SOURCES = REPO_ROOT / "_data" / "digest_sources.yml"
DATA_DIGESTS_DIR = REPO_ROOT / "_data" / "digests"
DIGESTS_DIR = REPO_ROOT / "_digests"
ZH_DIGESTS_DIR = REPO_ROOT / "_digests_zh"
CARD_DIR = REPO_ROOT / "assets" / "img" / "digests"
DEFAULT_SITE_URL = "https://long19950304.github.io"


def _die(msg: str, code: int = 2) -> None:
    print(f"error: {msg}", file=sys.stderr)
    raise SystemExit(code)


def _ensure_dirs() -> None:
    DATA_DIGESTS_DIR.mkdir(parents=True, exist_ok=True)
    DIGESTS_DIR.mkdir(parents=True, exist_ok=True)
    ZH_DIGESTS_DIR.mkdir(parents=True, exist_ok=True)
    CARD_DIR.mkdir(parents=True, exist_ok=True)


def _parse_date(s: str) -> dt.date:
    try:
        return dt.date.fromisoformat(s)
    except ValueError:
        _die(f"invalid --date '{s}', expected YYYY-MM-DD")


def _load_sources() -> list[dict[str, Any]]:
    if not DATA_SOURCES.exists():
        _die(f"missing {DATA_SOURCES}")
    raw = yaml.safe_load(DATA_SOURCES.read_text(encoding="utf-8")) or {}
    sources = raw.get("sources", [])
    if not isinstance(sources, list) or not sources:
        _die(f"no sources defined in {DATA_SOURCES}")
    return sources


def _norm(s: str) -> str:
    s = s.strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s


def _pick_entry_time(entry: Any) -> dt.datetime | None:
    # feedparser yields either .published_parsed or .updated_parsed
    t = getattr(entry, "published_parsed", None) or getattr(entry, "updated_parsed", None)
    if not t:
        return None
    return dt.datetime(*t[:6], tzinfo=dt.timezone.utc)


def _clean_title(title: str) -> str:
    title = re.sub(r"\s+", " ", title or "").strip()
    # arXiv RSS titles sometimes include extra whitespace/line breaks.
    return title


def _strip_html(s: str) -> str:
    # RSS summaries often include HTML tags. Keep a plain-text snippet for drafting.
    s = html.unescape(s or "")
    s = re.sub(r"<[^>]+>", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s


def _first_sentence(s: str, max_len: int = 160) -> str:
    s = re.sub(r"\s+", " ", (s or "").strip())
    if not s:
        return ""
    # Heuristic sentence split. Good enough for drafting.
    m = re.split(r"(?<=[.!?])\s+", s, maxsplit=1)
    out = (m[0] if m else s).strip()
    if len(out) > max_len:
        out = out[: max_len - 1].rstrip() + "…"
    return out


def _truncate(s: str, max_len: int) -> str:
    s = re.sub(r"\s+", " ", (s or "").strip())
    if len(s) <= max_len:
        return s
    return s[: max_len - 1].rstrip() + "…"


def _draft_items(
    sources: list[dict[str, Any]],
    since_utc: dt.datetime,
    max_items: int,
) -> list[dict[str, Any]]:
    items: list[dict[str, Any]] = []
    for src in sources:
        url = src.get("url", "").strip()
        if not url:
            continue
        feed = feedparser.parse(url)
        for e in getattr(feed, "entries", []) or []:
            when = _pick_entry_time(e)
            if when and when < since_utc:
                continue
            title = _clean_title(getattr(e, "title", "") or "")
            link = (getattr(e, "link", "") or "").strip()
            summary = _strip_html(getattr(e, "summary", "") or getattr(e, "description", "") or "")
            if not title or not link:
                continue
            # Provide draft-level snippets (user should rewrite for quality).
            takeaway = _truncate(summary, 360) if summary else ""
            why = _first_sentence(summary, 140) if summary else ""
            items.append(
                {
                    "category": src.get("category", "").strip() or "Misc",
                    "title": title,
                    "why": why,
                    "takeaway": takeaway,
                    "prompt": "",
                    "url": link,
                    "source": src.get("name", "").strip() or src.get("id", "").strip(),
                    "published_utc": when.isoformat() if when else "",
                    # Chinese fields are intentionally left blank for human curation.
                    "title_zh": "",
                    "why_zh": "",
                    "takeaway_zh": "",
                    "prompt_zh": "",
                }
            )

    # Deduplicate by URL, then by normalized title.
    seen_url: set[str] = set()
    seen_title: set[str] = set()
    deduped: list[dict[str, Any]] = []
    for it in sorted(items, key=lambda x: x.get("published_utc", ""), reverse=True):
        url = it.get("url", "")
        tnorm = _norm(it.get("title", ""))
        if url in seen_url or tnorm in seen_title:
            continue
        seen_url.add(url)
        seen_title.add(tnorm)
        deduped.append(it)

    return deduped[: max_items or 200]


def _save_yaml(path: Path, payload: Any) -> None:
    path.write_text(yaml.safe_dump(payload, sort_keys=False, allow_unicode=True), encoding="utf-8")


def _load_digest_yaml(path: Path) -> dict[str, Any]:
    if not path.exists():
        _die(f"missing digest file: {path}")
    raw = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
    if not isinstance(raw, dict):
        _die(f"invalid digest yaml: {path}")
    return raw


def _group_by_category(items: list[dict[str, Any]]) -> list[tuple[str, list[dict[str, Any]]]]:
    groups: dict[str, list[dict[str, Any]]] = {}
    for it in items:
        cat = (it.get("category", "") or "Misc").strip()
        groups.setdefault(cat, []).append(it)
    # Preserve a sensible, stable ordering: CSS first, then AI, then others.
    order = [
        "CSS / AI & society",
        "AI frontier",
        "Digital health / health comm",
        "Education / learning sciences / edtech",
        "Misc",
    ]
    ordered: list[tuple[str, list[dict[str, Any]]]] = []
    for k in order:
        if k in groups:
            ordered.append((k, groups.pop(k)))
    for k in sorted(groups.keys()):
        ordered.append((k, groups[k]))
    return ordered


CAT_ZH = {
    "CSS / AI & society": "CSS / AI 与社会",
    "AI frontier": "AI 前沿",
    "Digital health / health comm": "数字健康 / 健康传播",
    "Education / learning sciences / edtech": "教育 / 学习科学 / 教育技术",
    "Misc": "其他",
}


def _pick_lang(it: dict[str, Any], key_en: str, key_zh: str, lang: str) -> str:
    if lang == "zh":
        v = (it.get(key_zh) or "").strip()
        if v:
            return v
        # Fallback to English if Chinese is missing.
    return (it.get(key_en) or "").strip()


def _font_paths(lang: str) -> dict[str, Path]:
    """
    Pick fonts that actually contain the glyphs we need.

    For zh, we must use a CJK font, otherwise Pillow will render tofu boxes.
    """
    if lang == "zh":
        candidates = [
            ("/System/Library/Fonts/Hiragino Sans GB.ttc", "regular"),
            ("/System/Library/Fonts/STHeiti Medium.ttc", "bold"),
            ("/System/Library/Fonts/STHeiti Light.ttc", "regular"),
            ("/System/Library/Fonts/Supplemental/Songti.ttc", "regular"),
        ]
    else:
        # Prefer widely available macOS fonts.
        candidates = [
            ("/System/Library/Fonts/Supplemental/Arial.ttf", "regular"),
            ("/System/Library/Fonts/Supplemental/Arial Bold.ttf", "bold"),
            ("/System/Library/Fonts/Supplemental/Arial Unicode.ttf", "regular"),
            ("/System/Library/Fonts/Supplemental/Helvetica.ttc", "regular"),
        ]
    out: dict[str, Path] = {}
    for fp, role in candidates:
        p = Path(fp)
        if p.exists() and role not in out:
            out[role] = p
    return out


def _wrap(draw: ImageDraw.ImageDraw, text: str, font: ImageFont.FreeTypeFont, max_width: int) -> list[str]:
    """
    Simple word-wrapping that preserves spaces.

    Important: do NOT strip whitespace aggressively, otherwise words will run together
    in the rendered card (a common issue when splitting on whitespace).
    """
    text = re.sub(r"\s+", " ", (text or "").strip())
    if not text:
        return []

    words = text.split(" ")
    lines: list[str] = []
    cur = ""

    def flush() -> None:
        nonlocal cur
        if cur:
            lines.append(cur)
            cur = ""

    for w in words:
        test = w if not cur else f"{cur} {w}"
        if draw.textlength(test, font=font) <= max_width:
            cur = test
            continue

        # If a single token is too long, hard-wrap it by characters.
        if not cur and draw.textlength(w, font=font) > max_width:
            chunk = ""
            for ch in w:
                t2 = chunk + ch
                if draw.textlength(t2, font=font) <= max_width:
                    chunk = t2
                else:
                    if chunk:
                        lines.append(chunk)
                    chunk = ch
            if chunk:
                cur = chunk
            continue

        flush()
        cur = w

    flush()
    return lines


_URL_RE = re.compile(r"https?://\S+")


def _x_char_len(s: str) -> int:
    """
    Approximate X/Twitter length.

    X counts any URL as ~23 chars regardless of actual length. We approximate
    with 23 to split threads safely.
    """
    if not s:
        return 0
    urls = list(_URL_RE.findall(s))
    # Replace each URL with 23 chars in the count.
    return len(s) - sum(len(u) for u in urls) + 23 * len(urls)


def _digest_issue_urls(date: dt.date, site_url: str) -> dict[str, str]:
    base = (site_url or DEFAULT_SITE_URL).rstrip("/")
    return {
        "en": f"{base}/digest/{date.isoformat()}/",
        "zh": f"{base}/zh/digest/{date.isoformat()}/",
        "en_card": f"/assets/img/digests/{date.isoformat()}-en.png",
        "zh_card": f"/assets/img/digests/{date.isoformat()}-zh.png",
    }


def _format_item_bilingual(it: dict[str, Any]) -> str:
    t_en = (it.get("title") or "").strip()
    w_en = (it.get("why") or "").strip()
    take_en = (it.get("takeaway") or "").strip()
    p_en = (it.get("prompt") or "").strip()
    t_zh = (it.get("title_zh") or "").strip()
    w_zh = (it.get("why_zh") or "").strip()
    take_zh = (it.get("takeaway_zh") or "").strip()
    p_zh = (it.get("prompt_zh") or "").strip()
    url = (it.get("url") or "").strip()

    en = t_en
    if w_en:
        en = f"{en} — {w_en}"

    zh = t_zh or ""
    if zh and w_zh:
        zh = f"{zh} — {w_zh}"
    elif not zh and w_zh:
        zh = w_zh

    # Professional bulletin: one concise takeaway line (no "my take"/first-person labels).
    # LinkedIn will auto-link raw URLs, so we keep the URL on its own line.
    tl_en = _first_sentence(take_en, 200) if take_en else ""
    tl_zh = _first_sentence(take_zh, 140) if take_zh else ""

    lines: list[str] = []
    if en:
        lines.append(f"- {en} — {tl_en}" if tl_en else f"- {en}")
    if zh:
        lines.append(f"  {zh} — {tl_zh}" if tl_zh else f"  {zh}")
    if url:
        lines.append(f"  {url}")
    return "\n".join(lines).strip()


def _format_linkedin_post(
    date: dt.date,
    digest: dict[str, Any],
    site_url: str,
    *,
    text_mode: str = "bilingual",
) -> str:
    items = digest.get("items", [])
    groups = _group_by_category(items)
    urls = _digest_issue_urls(date, site_url)

    title_en = (digest.get("title") or f"Daily Digest — {date.isoformat()}").strip()
    title_zh = (digest.get("title_zh") or f"每日简报 — {date.isoformat()}").strip()

    def blurb(it: dict[str, Any], lang: str) -> str:
        # For social, prefer the short "why" line (less templated, avoids mid-sentence truncation).
        why = _pick_lang(it, "why", "why_zh", lang)
        if why:
            return why
        take = _pick_lang(it, "takeaway", "takeaway_zh", lang)
        return _first_sentence(take, 110 if lang != "zh" else 70)

    if text_mode == "en":
        lines: list[str] = [
            f"{title_en}",
            "",
            "Cards attached (EN + 中文 card).",
            "",
            f"Full list: {urls['en']}",
            "",
            "Highlights (clickable links):",
            "",
        ]
    else:
        lines = [
            f"{title_en} / {title_zh}",
            "",
            "EN + 中文 cards attached. Full lists:",
            "附英文/中文两张卡片；完整列表：",
        ]

        lines.extend(
            [
                "",
                f"EN list: {urls['en']}",
                f"中文列表: {urls['zh']}",
                "",
                "Bulletin (clickable links) / 快报（可点击链接）：",
                "",
            ]
        )

    max_items_total = 6 if text_mode == "en" else 10
    rendered = 0
    for cat, cat_items in groups:
        if not cat_items:
            continue
        # Category header
        if text_mode == "en":
            lines.append(cat)
        else:
            lines.append(f"{cat} / {CAT_ZH.get(cat, cat)}")
        for it in cat_items:
            if rendered >= max_items_total:
                break
            t_en = (it.get("title") or "").strip()
            t_zh = (it.get("title_zh") or "").strip()
            u = (it.get("url") or "").strip()
            if not t_en or not u:
                continue
            b_en = blurb(it, "en")
            b_zh = blurb(it, "zh") if text_mode != "en" else ""
            # One compact bilingual line per item; details live on the digest page.
            head = f"- {t_en}"
            if text_mode != "en" and t_zh and t_zh != t_en:
                head += f" / {t_zh}"
            if b_en:
                head += f" — {b_en}"
            if text_mode != "en" and b_zh and b_zh != b_en:
                head += f" / {b_zh}"
            lines.append(head)
            lines.append(f"  {u}")
            rendered += 1
        lines.append("")
        if rendered >= max_items_total:
            break

    if text_mode != "en":
        # Discussion prompts (max 2) at the end.
        prompts: list[tuple[str, str]] = []
        for it in items:
            p_en = (it.get("prompt") or "").strip()
            p_zh = (it.get("prompt_zh") or "").strip()
            if p_en or p_zh:
                prompts.append((p_en, p_zh))
        if prompts:
            lines.append("Open questions / 开放问题：")
            for p_en, p_zh in prompts[:2]:
                if p_en and p_zh:
                    lines.append(f"- {p_en} / {p_zh}")
                elif p_en:
                    lines.append(f"- {p_en}")
                elif p_zh:
                    lines.append(f"- {p_zh}")
            lines.append("")

    return "\n".join(lines).rstrip() + "\n"


def _format_x_thread(
    date: dt.date,
    digest: dict[str, Any],
    site_url: str,
    *,
    text_mode: str = "bilingual",
) -> list[str]:
    items = digest.get("items", [])
    groups = _group_by_category(items)
    urls = _digest_issue_urls(date, site_url)

    if text_mode == "en":
        # Single post for X: keep it lightweight; attach BOTH cards here.
        picks: list[tuple[str, str, str]] = []
        for _, cat_items in groups:
            for it in cat_items:
                t = (it.get("title") or "").strip()
                w = (it.get("why") or "").strip()
                u = (it.get("url") or "").strip()
                if t and u:
                    picks.append((t, w, u))
        picks = picks[:2]  # keep within X length limits

        lines = [
            f"Daily Digest ({date.isoformat()}) — cards attached (EN + 中文).",
            f"Full list: {urls['en']}",
            "",
        ]
        for t, w, u in picks:
            line = f"- {t}"
            if w:
                line += f" — {w}"
            lines.extend([line, u, ""])
        return ["\n".join([ln for ln in lines if ln is not None]).strip()]

    # Tweet 1: short bilingual intro + canonical links (attach BOTH cards here).
    t0 = "\n".join(
        [
            f"Daily Digest / 每日简报 ({date.isoformat()})",
            "EN + 中文 cards attached.",
            f"EN: {urls['en']}",
            f"中文: {urls['zh']}",
            "",
            "Direct links in thread / 详细链接见串：",
        ]
    ).strip()

    tweets: list[str] = [t0]

    # Thread: compact per-item blocks (avoid orphan headings when splitting).
    blocks: list[str] = []
    for cat, cat_items in groups:
        if not cat_items:
            continue
        for it in cat_items[:10]:
            t_en = (it.get("title") or "").strip()
            w_en = (it.get("why") or "").strip()
            take_en = (it.get("takeaway") or "").strip()
            t_zh = (it.get("title_zh") or "").strip()
            w_zh = (it.get("why_zh") or "").strip()
            take_zh = (it.get("takeaway_zh") or "").strip()
            url = (it.get("url") or "").strip()

            cat_zh = CAT_ZH.get(cat, cat)
            cat_label = f"[{cat}]/{cat_zh}"

            tl_en = w_en or _first_sentence(take_en, 200)
            tl_zh = w_zh or _first_sentence(take_zh, 140)

            # Keep X readable: title + short notes + link.
            line = f"{cat_label} {t_en}".strip()
            if tl_en:
                line = f"{line}\nNote: {tl_en}"
            if t_zh:
                line = f"{line}\n{t_zh}"
            if tl_zh:
                line = f"{line}\n要点：{tl_zh}"
            if url:
                line = f"{line}\n{url}"
            blocks.append(line.strip())

    # Pack blocks into tweets with conservative length.
    cur: list[str] = []
    cur_len = 0
    max_len = 265  # keep headroom for platform differences
    for b in blocks:
        add = (b + "\n\n").strip() if b else ""
        if not add:
            continue
        add_len = _x_char_len(add) + (2 if cur else 0)
        if cur and cur_len + add_len > max_len:
            tweets.append("\n\n".join(cur).strip())
            cur = [b]
            cur_len = _x_char_len(b)
            continue
        if cur:
            cur_len += _x_char_len("\n\n" + b)
            cur.append(b)
        else:
            cur = [b]
            cur_len = _x_char_len(b)
    if cur:
        tweets.append("\n\n".join(cur).strip())

    return tweets


def render_card(date: dt.date, items: list[dict[str, Any]], out_path: Path, *, lang: str) -> None:
    # 4:5 aspect ratio is friendly for both LinkedIn and X.
    w, h = 1080, 1350
    # Professional / restrained: clean, bright background; no decorative textures.
    bg = (252, 252, 253)  # near-white
    ink = (15, 23, 42)    # slate-900
    sub = (51, 65, 85)    # slate-700
    faint = (226, 232, 240)

    img = Image.new("RGB", (w, h), bg)
    draw = ImageDraw.Draw(img)

    fonts = _font_paths(lang)
    font_title = ImageFont.truetype(str(fonts.get("bold", fonts.get("regular"))), 52) if fonts else ImageFont.load_default()
    font_h2 = ImageFont.truetype(str(fonts.get("bold", fonts.get("regular"))), 28) if fonts else ImageFont.load_default()
    font_small = ImageFont.truetype(str(fonts.get("regular", fonts.get("bold"))), 22) if fonts else ImageFont.load_default()
    font_item_title = ImageFont.truetype(str(fonts.get("bold", fonts.get("regular"))), 28) if fonts else ImageFont.load_default()
    font_item_body = ImageFont.truetype(str(fonts.get("regular", fonts.get("bold"))), 24) if fonts else ImageFont.load_default()

    pad = 72
    x = pad
    y = 64

    def round_rect_outline(x0: int, y0: int, x1: int, y1: int, r: int) -> None:
        # Monochrome pill with a thin outline (more "academic", less "poster-like").
        draw.rounded_rectangle((x0, y0, x1, y1), radius=r, outline=faint, width=2, fill=bg)

    title = "Daily Digest" if lang != "zh" else "每日简报"
    draw.text((x, y), title, fill=ink, font=font_title)
    y += 58

    date_str = date.isoformat()
    subtitle = "A quick bulletin of what I'm reading today." if lang != "zh" else "今天在读的内容速览。"
    draw.text((x, y), date_str + "  ·  " + subtitle, fill=sub, font=font_small)
    y += 34

    # Top rule
    draw.line((x, y, w - pad, y), fill=faint, width=2)
    y += 22

    groups = _group_by_category(items)
    max_items_total = 10
    rendered = 0

    for cat, cat_items in groups:
        if rendered >= max_items_total:
            break
        if not cat_items:
            continue
        cat_label = cat if lang != "zh" else CAT_ZH.get(cat, cat)
        # Category chip (outlined, monochrome)
        chip_h = 30
        chip_w = int(draw.textlength(cat_label, font=font_small)) + 28
        round_rect_outline(x, y, x + chip_w, y + chip_h, 14)
        draw.text((x + 14, y + 5), cat_label, fill=sub, font=font_small)
        y += chip_h + 12

        for it in cat_items:
            if rendered >= max_items_total:
                break
            t = _pick_lang(it, "title", "title_zh", lang)
            why = _pick_lang(it, "why", "why_zh", lang)
            take = _pick_lang(it, "takeaway", "takeaway_zh", lang)
            # Card should stay very scannable: 1 title line + 1 TL;DR line.
            tl = why or _first_sentence(take, 140)

            if not t:
                continue

            # Title (allow 2 lines so long titles stay readable).
            t_lines = _wrap(draw, t, font_item_title, max_width=w - pad * 2)[:2]
            for ln in t_lines:
                draw.text((x, y), ln, fill=ink, font=font_item_title)
                y += 34
            y += 2

            if tl:
                # Keep the blurb compact, but allow up to 2 lines.
                tl_lines = _wrap(draw, tl, font_item_body, max_width=w - pad * 2)[:2]
                for ln in tl_lines:
                    draw.text((x, y), ln, fill=sub, font=font_item_body)
                    y += 30

            y += 14
            rendered += 1

        y += 8
        if y > h - 220:
            break

    # Bottom rule + footer
    y = h - 160
    draw.line((x, y, w - pad, y), fill=faint, width=2)
    y += 22
    footer = "Zhilong George Zhao | @longlalaland | long19950304.github.io"
    draw.text((x, y), footer, fill=sub, font=font_small)

    out_path.parent.mkdir(parents=True, exist_ok=True)
    img.save(out_path, format="PNG", optimize=True, compress_level=9)


def _md_for_lang(date: dt.date, digest: dict[str, Any], *, lang: str) -> tuple[Path, Path]:
    items = digest.get("items", [])
    if not isinstance(items, list):
        _die("digest.items must be a list")
    if not items:
        _die("digest has no items; skip build or add items first")

    # Image card
    suffix = "zh" if lang == "zh" else "en"
    card_path = CARD_DIR / f"{date.isoformat()}-{suffix}.png"
    render_card(date, items, card_path, lang=lang)

    # Markdown page (collection item)
    out_dir = ZH_DIGESTS_DIR if lang == "zh" else DIGESTS_DIR
    out_dir.mkdir(parents=True, exist_ok=True)
    md_path = out_dir / f"{date.isoformat()}.md"

    title = digest.get("title") or f"Daily Digest - {date.isoformat()}"
    if lang == "zh":
        title = digest.get("title_zh") or f"每日简报 - {date.isoformat()}"

    groups = _group_by_category(items)
    note = (digest.get("note_zh") if lang == "zh" else digest.get("note")) or ""
    note = note.strip()

    lines: list[str] = [
        "---",
        "layout: page",
        f'title: "{title}"',
        f"lang: {lang}",
        f"permalink: /{'zh/' if lang == 'zh' else ''}digest/{date.isoformat()}/",
        f"digest_date: {date.isoformat()}",
        f"card_image: /assets/img/digests/{date.isoformat()}-{suffix}.png",
        f"translation_key: digest-{date.isoformat()}",
        "---",
        "",
        f"![Daily digest card](/assets/img/digests/{date.isoformat()}-{suffix}.png)",
        "",
    ]
    if note:
        lines.extend([note, ""])
    lines.extend(["## Links" if lang != "zh" else "## 链接", ""])

    for cat, cat_items in groups:
        if not cat_items:
            continue
        cat_label = cat if lang != "zh" else CAT_ZH.get(cat, cat)
        lines.append(f"### {cat_label}")
        lines.append("")
        for it in cat_items:
            t = _pick_lang(it, "title", "title_zh", lang)
            u = it.get("url", "").strip()
            why = _pick_lang(it, "why", "why_zh", lang)
            takeaway = _pick_lang(it, "takeaway", "takeaway_zh", lang)
            prompt = _pick_lang(it, "prompt", "prompt_zh", lang)
            if not t or not u:
                continue
            line = f"- [{t}]({u})"
            if why:
                line = f"{line} - {why}"
            lines.append(line)
            if takeaway:
                if lang != "zh":
                    lines.append(f"  - Takeaway: {takeaway}")
                else:
                    lines.append(f"  - 要点: {takeaway}")
            if prompt:
                if lang != "zh":
                    lines.append(f"  - Open question: {prompt}")
                else:
                    lines.append(f"  - 开放问题: {prompt}")
        lines.append("")

    md_path.write_text("\n".join(lines).rstrip() + "\n", encoding="utf-8")
    return md_path, card_path


def build_digest(date: dt.date, digest: dict[str, Any]) -> list[tuple[str, Path, Path]]:
    out: list[tuple[str, Path, Path]] = []
    out.append(("en",) + _md_for_lang(date, digest, lang="en"))
    out.append(("zh",) + _md_for_lang(date, digest, lang="zh"))
    return out


def cmd_draft(args: argparse.Namespace) -> None:
    _ensure_dirs()
    date = _parse_date(args.date)
    sources = _load_sources()
    # Since: last N hours from now (UTC). This keeps drafts useful for daily runs.
    since_utc = dt.datetime.now(dt.timezone.utc) - dt.timedelta(hours=args.hours)
    items = _draft_items(sources, since_utc=since_utc, max_items=args.max_items)

    out = DATA_DIGESTS_DIR / f"{date.isoformat()}.yml"
    if out.exists() and not args.force:
        out = DATA_DIGESTS_DIR / f"{date.isoformat()}.draft.yml"

    payload = {
        "date": date.isoformat(),
        "title": f"Daily Digest - {date.isoformat()}",
        "title_zh": f"每日简报 - {date.isoformat()}",
        "note": "",
        "note_zh": "",
        "items": items,
    }
    _save_yaml(out, payload)
    print(f"Wrote {out.relative_to(REPO_ROOT)} ({len(items)} items).")
    print("Next: edit `why` (short), `takeaway` (1–2 sentences), `prompt` (1 question) + fill *_zh, then run:")
    print(f"  {REPO_ROOT}/bin/digest build --date {date.isoformat()}")


def cmd_build(args: argparse.Namespace) -> None:
    _ensure_dirs()
    date = _parse_date(args.date)
    digest_path = DATA_DIGESTS_DIR / f"{date.isoformat()}.yml"
    if not digest_path.exists():
        # If only draft exists, use it.
        draft = DATA_DIGESTS_DIR / f"{date.isoformat()}.draft.yml"
        if draft.exists():
            digest_path = draft
        else:
            _die(f"missing digest YAML for {date.isoformat()} (expected {digest_path})")
    digest = _load_digest_yaml(digest_path)
    results = build_digest(date, digest)
    for lang, md_path, card_path in results:
        print(f"Wrote {md_path.relative_to(REPO_ROOT)} ({lang})")
        print(f"Wrote {card_path.relative_to(REPO_ROOT)} ({lang})")


def cmd_social(args: argparse.Namespace) -> None:
    _ensure_dirs()
    date = _parse_date(args.date)
    digest_path = DATA_DIGESTS_DIR / f"{date.isoformat()}.yml"
    if not digest_path.exists():
        draft = DATA_DIGESTS_DIR / f"{date.isoformat()}.draft.yml"
        if draft.exists():
            digest_path = draft
        else:
            _die(f"missing digest YAML for {date.isoformat()} (expected {digest_path})")

    digest = _load_digest_yaml(digest_path)
    # Social requirement: each post should include BOTH EN + ZH card images.
    card_en = CARD_DIR / f"{date.isoformat()}-en.png"
    card_zh = CARD_DIR / f"{date.isoformat()}-zh.png"
    print("==== Attach images (EN + ZH) ====")
    print(f"EN card: {card_en}")
    print(f"ZH card: {card_zh}")
    if not card_en.exists() or not card_zh.exists():
        print("(Tip) Run `./bin/digest build --date YYYY-MM-DD` first to generate the cards.")
    print("")

    if args.platform in ("linkedin", "both"):
        print("==== LinkedIn (copy/paste) ====")
        print(_format_linkedin_post(date, digest, site_url=args.site_url, text_mode=args.text))

    if args.platform in ("x", "both"):
        print("==== X thread (copy/paste) ====")
        tweets = _format_x_thread(date, digest, site_url=args.site_url, text_mode=args.text)
        total = len(tweets)
        for i, t in enumerate(tweets, start=1):
            print(f"\n--- Tweet {i}/{total} ---\n{t}\n")


def main(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(prog="digest")
    sub = parser.add_subparsers(dest="cmd", required=True)

    p_draft = sub.add_parser("draft", help="Draft a digest YAML from RSS/Atom sources")
    p_draft.add_argument("--date", required=True, help="YYYY-MM-DD (label for this issue)")
    p_draft.add_argument("--hours", type=int, default=36, help="Look back window (UTC), default: 36")
    p_draft.add_argument("--max-items", type=int, default=40, help="Max candidate items to write, default: 40")
    p_draft.add_argument("--force", action="store_true", help="Overwrite existing YYYY-MM-DD.yml")
    p_draft.set_defaults(func=cmd_draft)

    p_build = sub.add_parser("build", help="Build digest page + image card from YAML")
    p_build.add_argument("--date", required=True, help="YYYY-MM-DD")
    p_build.set_defaults(func=cmd_build)

    p_social = sub.add_parser("social", help="Generate social post text (LinkedIn + X)")
    p_social.add_argument("--date", required=True, help="YYYY-MM-DD")
    p_social.add_argument(
        "--platform",
        choices=["both", "linkedin", "x"],
        default="both",
        help="Which post text to emit, default: both",
    )
    p_social.add_argument(
        "--text",
        choices=["en", "bilingual"],
        default="bilingual",
        help="Text mode for posts; note: cards are always EN+ZH. Default: bilingual",
    )
    p_social.add_argument(
        "--site-url",
        default=DEFAULT_SITE_URL,
        help=f"Canonical site URL for digest links, default: {DEFAULT_SITE_URL}",
    )
    p_social.set_defaults(func=cmd_social)

    args = parser.parse_args(argv)
    args.func(args)
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
