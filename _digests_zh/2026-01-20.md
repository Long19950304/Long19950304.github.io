---
layout: page
title: "每日简报 — 2026-01-20"
lang: zh
permalink: /zh/digest/2026-01-20/
digest_date: 2026-01-20
card_image: /assets/img/digests/2026-01-20-zh.png
translation_key: digest-2026-01-20
---

![Daily digest card](/assets/img/digests/2026-01-20-zh.png)

本期为阅读记录与要点摘录；后续会选 1–2 条进一步展开。

## 链接

### CSS / AI 与社会

- [AI 迎合：用户如何标记与回应](https://arxiv.org/abs/2601.10467v1) - 提供可观测的证据线索，帮助识别/处理过度迎合的 LLM 行为。
  - 要点: 分析用户对迎合行为的识别与反馈，并给出用于信任/安全评估的可观测线索。
  - 开放问题: 助手应如何在“礼貌”与“必要的不同意”之间平衡，而不滑向迎合？

### AI 前沿

- [Differential Transformer V2](https://huggingface.co/blog/microsoft/diff-attn-v2) - 一种新的注意力变体，聚焦更高效的长上下文建模。
  - 要点: 提出差分注意力以提升长上下文计算效率；可作为与标准 Transformer 对照的注意力变体。
- [OpenAI 与 Cerebras 合作](https://openai.com/index/cerebras-partnership) - 值得关注的算力/推理合作，可能影响速度与成本。
  - 要点: 显示推理侧对专用硬件合作的推进，可能影响推理延迟/成本与可用性。
- [Open Responses：你需要了解什么](https://huggingface.co/blog/open-responses) - 一个可操作的多模型工作流，用于对比与整合大模型输出。
  - 要点: 给出多模型对照与整合的工作流思路，强调多样性与验证。

### 教育 / 学习科学 / 教育技术

- [对话式考试：AI 时代可扩展的评估设计](https://arxiv.org/abs/2601.10691v1) - 一种面向 AI 时代的评估形式，尽量保持测评的有效性。
  - 要点: 以对话式交互评估推理与解释能力，旨在 AI 可用环境下保持测评有效性。
  - 开放问题: 哪些规则/机制能让对话式测评更公平、可扩展、并降低主观性？
- [用大语言模型评估高等教育课程的 21 世纪能力：性能基准与推理式提示策略](https://arxiv.org/abs/2601.10983v1) - 针对课程能力评估任务，对模型表现与提示策略进行基准测试。
  - 要点: 对 LLM 课程能力评估进行基准测试并比较提示策略，为自动化课程审计提供方法依据。
- [aiPlato：用于物理作业的 AI 辅导与分步反馈系统](https://arxiv.org/abs/2601.09965v1) - 强调分步反馈的辅导设计，更贴近学生的学习过程。
  - 要点: 分步反馈式辅导设计，减少直接给答案，强调过程支架。
- [拿出你的计算器：用“LLM 学生模拟”估计题目真实难度](https://arxiv.org/abs/2601.09953v1) - 用模拟的“LLM 学生”来估计题目难度，服务于测评设计。
  - 要点: 用 LLM 学生模拟估计题目难度，适用于真实作答数据不足场景，但需要校准验证。
