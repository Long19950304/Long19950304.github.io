---
layout: page
title: "每日简报 — 2026-01-20"
lang: zh
permalink: /zh/digest/2026-01-20/
digest_date: 2026-01-20
card_image: /assets/img/digests/2026-01-20-zh.png
translation_key: digest-2026-01-20
---

![Daily digest card](/assets/img/digests/2026-01-20-zh.png)

## 链接

### CSS / AI 与社会

- [AI 迎合：用户如何标记与回应](https://arxiv.org/abs/2601.10467v1) - 提供可观测的证据线索，帮助识别/处理过度迎合的 LLM 行为。
  - 要点: 研究用户如何识别并回应“迎合型”助手行为；给出可观测信号，并讨论其对信任与安全评估的启示。
  - 讨论: 助手应如何在“礼貌”与“必要的不同意”之间平衡，而不滑向迎合？

### AI 前沿

- [Differential Transformer V2](https://huggingface.co/blog/microsoft/diff-attn-v2) - 一种新的注意力变体，聚焦更高效的长上下文建模。
  - 要点: 提出一种差分注意力机制（Diff Attn v2）以提升长上下文的效率；可作为对比不同注意力变体与标准 Transformer 的基准参考。
- [OpenAI 与 Cerebras 合作](https://openai.com/index/cerebras-partnership) - 值得关注的算力/推理合作，可能影响速度与成本。
  - 要点: 反映出模型方继续推进与专用推理硬件的合作；这可能改变延迟/成本的权衡，并影响“高速推理”在规模化场景中的可获得性。
- [Open Responses：你需要了解什么](https://huggingface.co/blog/open-responses) - 一个可操作的多模型工作流，用于对比与整合大模型输出。
  - 要点: 介绍一种“Open Responses”的模式：对比多个模型并整合输出；适合用“多样性 + 校验”来构建更稳健的工作流。

### 教育 / 学习科学 / 教育技术

- [对话式考试：AI 时代可扩展的评估设计](https://arxiv.org/abs/2601.10691v1) - 一种面向 AI 时代的评估形式，尽量保持测评的有效性。
  - 要点: 提出“对话式考试”，通过交互过程评估推理，而不只看最终答案；目标是在学生可用 AI 工具的时代保持测评有效性。
  - 讨论: 哪些规则/机制能让对话式测评更公平、可扩展、并降低主观性？
- [用大语言模型评估高等教育课程的 21 世纪能力：性能基准与推理式提示策略](https://arxiv.org/abs/2601.10983v1) - 针对课程能力评估任务，对模型表现与提示策略进行基准测试。
  - 要点: 对“课程 21 世纪能力评估”任务进行大模型基准测试，并探索推理式提示策略；为更可靠的自动化课程审计提供方法线索。
- [aiPlato：用于物理作业的 AI 辅导与分步反馈系统](https://arxiv.org/abs/2601.09965v1) - 强调分步反馈的辅导设计，更贴近学生的学习过程。
  - 要点: 一种强调“分步反馈”的 AI 辅导设计，而不是直接给出完整解答；提供了更贴近支架式学习的具体设计模式。
- [拿出你的计算器：用“LLM 学生模拟”估计题目真实难度](https://arxiv.org/abs/2601.09953v1) - 用模拟的“LLM 学生”来估计题目难度，服务于测评设计。
  - 要点: 用“LLM 学生模拟”来估计题目难度；当真实作答数据不足时，为题目分析提供一种方法思路。
