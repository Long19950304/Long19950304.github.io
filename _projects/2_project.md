---
layout: page
title: "Reliable LLM-Assisted Qualitative Analysis"
description: "Benchmarks, calibration, and QA for human/LLM hybrid coding in communication research."
title_zh: "LLM 辅助质性分析的可靠性"
description_zh: "面向传播研究的人机协同编码：基准评测、校准与质量保障（QA），让复杂质性分析更可辩护。"
img: /assets/img/projects/llm-evaluation.svg
importance: 2
category: research
---

I work on reliability and evaluation for LLM-assisted qualitative analysis: how to design benchmarks, calibrate outputs, and run QA for complex coding tasks so results remain defensible in real research workflows.

Representative directions:
- Coding quality assessment and calibration (complex labels, multi-stage rubrics, error analysis)
- Benchmark design for domain-specific annotation tasks
- Reproducible pipelines for human/LLM hybrid coding (auditability and responsible use)
