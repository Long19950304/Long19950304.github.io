date: "2026-01-20"
title: "Daily Digest — 2026-01-20"
title_zh: "每日简报 — 2026-01-20"
note: "This issue is a reading log and short takeaways; 1–2 items may be expanded later."
note_zh: "本期为阅读记录与要点摘录；后续会选 1–2 条进一步展开。"
items:
  - category: "AI frontier"
    title: "Differential Transformer V2"
    title_zh: "Differential Transformer V2"
    why: "A new attention variant aimed at more efficient long-context modeling."
    why_zh: "一种新的注意力变体，聚焦更高效的长上下文建模。"
    takeaway: "Proposes a differential attention mechanism (Diff Attn v2) to improve long-context efficiency; a concrete attention variant to compare against standard Transformers."
    takeaway_zh: "提出差分注意力以提升长上下文计算效率；可作为与标准 Transformer 对照的注意力变体。"
    prompt: ""
    prompt_zh: ""
    url: "https://huggingface.co/blog/microsoft/diff-attn-v2"
    source: "Hugging Face Blog"

  - category: "AI frontier"
    title: "OpenAI partners with Cerebras"
    title_zh: "OpenAI 与 Cerebras 合作"
    why: "A notable infra/inference partnership; watch for speed/cost implications."
    why_zh: "值得关注的算力/推理合作，可能影响速度与成本。"
    takeaway: "Signals continued investment in specialized inference hardware partnerships, with implications for inference latency, cost, and availability."
    takeaway_zh: "显示推理侧对专用硬件合作的推进，可能影响推理延迟/成本与可用性。"
    prompt: ""
    prompt_zh: ""
    url: "https://openai.com/index/cerebras-partnership"
    source: "OpenAI Blog"

  - category: "AI frontier"
    title: "Open Responses: What you need to know"
    title_zh: "Open Responses：你需要了解什么"
    why: "A practical multi-model workflow for comparing and integrating LLM outputs."
    why_zh: "一个可操作的多模型工作流，用于对比与整合大模型输出。"
    takeaway: "Outlines an 'open responses' workflow for comparing multiple models and synthesizing outputs, emphasizing diversity and verification."
    takeaway_zh: "给出多模型对照与整合的工作流思路，强调多样性与验证。"
    prompt: ""
    prompt_zh: ""
    url: "https://huggingface.co/blog/open-responses"
    source: "Hugging Face Blog"

  - category: "CSS / AI & society"
    title: "AI Sycophancy: How Users Flag and Respond"
    title_zh: "AI 迎合：用户如何标记与回应"
    why: "Empirical signals for detecting/handling overly agreeable LLM behavior."
    why_zh: "提供可观测的证据线索，帮助识别/处理过度迎合的 LLM 行为。"
    takeaway: "Examines how users detect and respond to sycophantic assistant behavior, and proposes observable signals relevant to trust and safety evaluation."
    takeaway_zh: "分析用户对迎合行为的识别与反馈，并给出用于信任/安全评估的可观测线索。"
    prompt: "How should assistants balance politeness vs disagreement without drifting into sycophancy?"
    prompt_zh: "助手应如何在“礼貌”与“必要的不同意”之间平衡，而不滑向迎合？"
    url: "https://arxiv.org/abs/2601.10467v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "The Conversational Exam: A Scalable Assessment Design for the AI Era"
    title_zh: "对话式考试：AI 时代可扩展的评估设计"
    why: "An assessment format designed to stay meaningful when students have AI."
    why_zh: "一种面向 AI 时代的评估形式，尽量保持测评的有效性。"
    takeaway: "Proposes conversational exams that assess reasoning through interaction (not only final answers), designed to remain meaningful when AI tools are available."
    takeaway_zh: "以对话式交互评估推理与解释能力，旨在 AI 可用环境下保持测评有效性。"
    prompt: "What guardrails would make conversational assessment fair, scalable, and less subjective?"
    prompt_zh: "哪些规则/机制能让对话式测评更公平、可扩展、并降低主观性？"
    url: "https://arxiv.org/abs/2601.10691v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "Evaluating 21st-Century Competencies in Postsecondary Curricula with Large Language Models: Performance Benchmarking and Reasoning-Based Prompting Strategies"
    title_zh: "用大语言模型评估高等教育课程的 21 世纪能力：性能基准与推理式提示策略"
    why: "Benchmarks LLMs for curricular competency evaluation and prompting strategies."
    why_zh: "针对课程能力评估任务，对模型表现与提示策略进行基准测试。"
    takeaway: "Benchmarks LLMs for evaluating 21st-century competencies in curricula and compares prompting strategies, informing more reliable automated curriculum auditing."
    takeaway_zh: "对 LLM 课程能力评估进行基准测试并比较提示策略，为自动化课程审计提供方法依据。"
    prompt: ""
    prompt_zh: ""
    url: "https://arxiv.org/abs/2601.10983v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "aiPlato: A Novel AI Tutoring and Step-wise Feedback System for Physics Homework"
    title_zh: "aiPlato：用于物理作业的 AI 辅导与分步反馈系统"
    why: "A tutoring design emphasizing step-wise feedback (closer to how students learn)."
    why_zh: "强调分步反馈的辅导设计，更贴近学生的学习过程。"
    takeaway: "An AI tutoring design centered on step-wise feedback (rather than full solutions), aligning with scaffolding-oriented learning support."
    takeaway_zh: "分步反馈式辅导设计，减少直接给答案，强调过程支架。"
    prompt: ""
    prompt_zh: ""
    url: "https://arxiv.org/abs/2601.09965v1"
    source: "arXiv"

  - category: "Education / learning sciences / edtech"
    title: "Take Out Your Calculators: Estimating the Real Difficulty of Question Items with LLM Student Simulations"
    title_zh: "拿出你的计算器：用“LLM 学生模拟”估计题目真实难度"
    why: "Uses simulated \"LLM students\" to estimate item difficulty for assessment design."
    why_zh: "用模拟的“LLM 学生”来估计题目难度，服务于测评设计。"
    takeaway: "Uses simulated 'LLM students' to estimate item difficulty, as a method option when real response data is limited (with calibration needs)."
    takeaway_zh: "用 LLM 学生模拟估计题目难度，适用于真实作答数据不足场景，但需要校准验证。"
    prompt: ""
    prompt_zh: ""
    url: "https://arxiv.org/abs/2601.09953v1"
    source: "arXiv"
